{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Heart issue .ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "16ASYUifuay4p9OQvJFeFMdVD_LZOVVub",
      "authorship_tag": "ABX9TyNZ5yipwR7Czd1TffzWTGTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyambhatt5/Data-science-Note-book/blob/main/Heart_issue_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9U3A5Zw_ZXT"
      },
      "source": [
        "import pandas\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns; sns.set()\r\n",
        "\r\n",
        "from sklearn import tree\r\n",
        "import graphviz \r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.feature_selection import chi2, f_classif\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.feature_selection import SelectFromModel\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import cross_val_predict\r\n",
        "\r\n",
        "from sklearn.preprocessing import normalize\r\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "from sklearn.naive_bayes import CategoricalNB\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\r\n",
        "from xgboost import plot_tree, plot_importance\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_selection import RFE\r\n",
        "\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
        "\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_TKX-nDEDPN"
      },
      "source": [
        "ha=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Practice Data Set/Data Set /healthcare-dataset-stroke-data.csv\")\r\n",
        "ha.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXq4dehoEgPE"
      },
      "source": [
        "ha.info()\r\n",
        "ha.isnull().sum()\r\n",
        "#ha.describe()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSJWIxttEwCr"
      },
      "source": [
        "ha = ha.dropna(axis=0,how='any')\r\n",
        "ha\r\n",
        "#df.fillna(df.mean())\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggJokNcnXBix"
      },
      "source": [
        "plt.figure(figsize=(12,8)) \r\n",
        "sns.heatmap(ha.corr(), annot=True, cmap='Dark2_r', linewidths = 2)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1GedbYBf9xa"
      },
      "source": [
        "sns.pairplot(ha, hue = 'stroke')\r\n",
        "sns.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzocSuvSFYEO"
      },
      "source": [
        "ohe=OneHotEncoder()\r\n",
        "lb=LabelEncoder()\r\n",
        "sc=MinMaxScaler()\r\n",
        "lr=LogisticRegression()\r\n",
        "dc=DecisionTreeClassifier()\r\n",
        "rf=RandomForestClassifier()\r\n",
        "ec=ExtraTreesClassifier()\r\n",
        "sv=SVC()\r\n",
        "gb=GaussianNB()\r\n",
        "gbc=GradientBoostingClassifier()\r\n",
        "\r\n",
        "l=[lr,dc,rf,ec,sv,gb,gbc]\r\n",
        "l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orMPKGZH3Ul"
      },
      "source": [
        "ct=make_column_transformer((MinMaxScaler(),make_column_selector(dtype_include= np.number)),\r\n",
        "                           (OneHotEncoder(),make_column_selector(dtype_include=object)))\r\n",
        "print(ct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu3jKP-LJ-Gl"
      },
      "source": [
        "X= ha.drop(columns=['id','stroke'])\r\n",
        "X.select_dtypes(include=np.number,exclude='category')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "#y=ha.stroke\r\n",
        "#y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tr_lVAKGV_uO"
      },
      "source": [
        "category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEkmaTxGKYY2"
      },
      "source": [
        "X=ct.fit_transform(X)\r\n",
        "print(X)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DXiYBUJLANm"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt9i4799LPzw"
      },
      "source": [
        "y=ha.stroke\r\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFXJZLm5OICy"
      },
      "source": [
        "print(X_train.shape)\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Xucq_sdaEz"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101) \r\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\r\n",
        "\r\n",
        "print(f'Total # of sample in whole dataset: {len(X)}')\r\n",
        "print(f'Total # of sample in train dataset: {len(X_train)}')\r\n",
        "print(f'Total # of sample in validation dataset: {len(X_valid)}')\r\n",
        "print(f'Total # of sample in test dataset: {len(X_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xreC58M5OVXR"
      },
      "source": [
        "models = {\r\n",
        "    'GaussianNB': GaussianNB(),\r\n",
        "    'MultinomialNB': MultinomialNB(),\r\n",
        "    'BernoulliNB': BernoulliNB(),\r\n",
        "    'LogisticRegression': LogisticRegression(),\r\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\r\n",
        "    'SupportVectorMachine': SVC(),\r\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\r\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(),\r\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\r\n",
        "    'Stochastic Gradient Descent':  SGDClassifier(max_iter=5000, random_state=0),\r\n",
        "    'Neural Nets': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1),\r\n",
        "    'XGBClassifier': XGBClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "modelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\r\n",
        "             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\r\n",
        "             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\r\n",
        "\r\n",
        "trainScores = []\r\n",
        "validationScores = []\r\n",
        "testScores = []\r\n",
        "\r\n",
        "for m in models:\r\n",
        "  model = models[m]\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  score = model.score(X_valid, y_valid)\r\n",
        "  #print(f'{m} validation score => {score*100}')\r\n",
        "    \r\n",
        "  print(f'{m}') \r\n",
        "  train_score = model.score(X_train, y_train)\r\n",
        "  print(f'Train score of trained model: {train_score*100}')\r\n",
        "  trainScores.append(train_score*100)\r\n",
        "\r\n",
        "  validation_score = model.score(X_valid, y_valid)\r\n",
        "  print(f'Validation score of trained model: {validation_score*100}')\r\n",
        "  validationScores.append(validation_score*100)\r\n",
        "\r\n",
        "  test_score = model.score(X_test, y_test)\r\n",
        "  print(f'Test score of trained model: {test_score*100}')\r\n",
        "  testScores.append(test_score*100)\r\n",
        "  print(\" \")\r\n",
        "    \r\n",
        "  y_predictions = model.predict(X_test)\r\n",
        "  conf_matrix = confusion_matrix(y_predictions, y_test)\r\n",
        "\r\n",
        "  print(f'Confussion Matrix: \\n{conf_matrix}\\n')\r\n",
        "\r\n",
        "  predictions = model.predict(X_test)\r\n",
        "  cm = confusion_matrix(predictions, y_test)\r\n",
        "\r\n",
        "  tn = conf_matrix[0,0]\r\n",
        "  fp = conf_matrix[0,1]\r\n",
        "  tp = conf_matrix[1,1]\r\n",
        "  fn = conf_matrix[1,0]\r\n",
        "  accuracy  = (tp + tn) / (tp + fp + tn + fn)\r\n",
        "  precision = tp / (tp + fp)\r\n",
        "  recall    = tp / (tp + fn)\r\n",
        "  f1score  = 2 * precision * recall / (precision + recall)\r\n",
        "  specificity = tn / (tn + fp)\r\n",
        "  print(f'Accuracy : {accuracy}')\r\n",
        "  print(f'Precision: {precision}')\r\n",
        "  print(f'Recall   : {recall}')\r\n",
        "  print(f'F1 score : {f1score}')\r\n",
        "  print(f'Specificity : {specificity}')\r\n",
        "  print(\"\") \r\n",
        "  print(f'Classification Report: \\n{classification_report(predictions, y_test)}\\n')\r\n",
        "  print(\"\")\r\n",
        "   \r\n",
        "  for m in range (1):\r\n",
        "    current = modelNames[m]\r\n",
        "    modelNames.remove(modelNames[m])\r\n",
        "\r\n",
        "  preds = model.predict(X_test)\r\n",
        "  confusion_matr = confusion_matrix(y_test, preds) #normalize = 'true'\r\n",
        "  plt.figure(figsize = (16,10))\r\n",
        "  plt.title(f'Heart Disease   -   Model: {current}   -   Accuracy: {test_score*100}')\r\n",
        "  sns.heatmap(confusion_matr, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},\r\n",
        "              xticklabels = ['Target - 0', 'Target - 1'],\r\n",
        "             yticklabels=['Target - 0', 'Target - 1']);\r\n",
        "  #plt.savefig(f'{current}.jpg')\r\n",
        "  print(\"############################################################################\")\r\n",
        "  print(\"\")\r\n",
        "  print(\"\")\r\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6ze6AVrRPhp"
      },
      "source": [
        "plt.figure(figsize=(20,10))\r\n",
        "plt.title('Train - Validation - Test Scores of Models', fontweight='bold', size = 24)\r\n",
        "\r\n",
        "barWidth = 0.25\r\n",
        " \r\n",
        "bars1 = trainScores\r\n",
        "bars2 = validationScores\r\n",
        "bars3 = testScores\r\n",
        " \r\n",
        "r1 = np.arange(len(bars1))\r\n",
        "r2 = [x + barWidth for x in r1]\r\n",
        "r3 = [x + barWidth for x in r2]\r\n",
        " \r\n",
        "plt.bar(r1, bars1, color='blue', width=barWidth, edgecolor='white', label='train', yerr=0.5,ecolor=\"black\",capsize=10)\r\n",
        "plt.bar(r2, bars2, color='#557f2d', width=barWidth, edgecolor='white', label='validation', yerr=0.5,ecolor=\"black\",capsize=10, alpha = .50)\r\n",
        "plt.bar(r3, bars3, color='red', width=barWidth, edgecolor='white', label='test', yerr=0.5,ecolor=\"black\",capsize=10, hatch = '-')\r\n",
        " \r\n",
        "modelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\r\n",
        "             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\r\n",
        "             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\r\n",
        "    \r\n",
        "plt.xlabel('Algorithms', fontweight='bold', size = 24)\r\n",
        "plt.ylabel('Scores', fontweight='bold', size = 24)\r\n",
        "plt.xticks([r + barWidth for r in range(len(bars1))], modelNames, rotation = 75)\r\n",
        " \r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TYE_0-ie1t3"
      },
      "source": [
        "for i in range(12):\r\n",
        "    print(f'Accuracy of {modelNames[i]} -----> {testScores[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaAQB5-3fFqr"
      },
      "source": [
        "models = {\r\n",
        "    'MultinomialNB': MultinomialNB(),\r\n",
        "    'BernoulliNB': BernoulliNB(),\r\n",
        "    'LogisticRegression': LogisticRegression(),\r\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\r\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\r\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\r\n",
        "    'Stochastic Gradient Descent':  SGDClassifier(max_iter=5000, random_state=0),\r\n",
        "    'XGBClassifier': XGBClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "for m in models:\r\n",
        "  model = models[m]\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  \r\n",
        "  print(f'{m}') \r\n",
        "  best_features = SelectFromModel(model)\r\n",
        "  best_features.fit(X, y)\r\n",
        "\r\n",
        "  transformedX = best_features.transform(X)\r\n",
        "  print(f\"Old Shape: {X.shape} New shape: {transformedX.shape}\")\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Qj34sVPfRae"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}