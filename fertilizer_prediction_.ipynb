{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fertilizer prediction .ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1udnUR8_OAdhl3Kc3RRKw-1Ny4wn-urQg",
      "authorship_tag": "ABX9TyO9CZfLnbavJxHt/947THm4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satyambhatt5/Data-science-Note-book/blob/main/fertilizer_prediction_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9hGROtzSX0a"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns; sns.set()\r\n",
        "\r\n",
        "from sklearn import tree\r\n",
        "import graphviz \r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "from pandas_profiling import ProfileReport\r\n",
        "\r\n",
        "from sklearn.feature_selection import SelectKBest\r\n",
        "from sklearn.feature_selection import chi2, f_classif\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.feature_selection import SelectFromModel\r\n",
        "from sklearn.svm import LinearSVC\r\n",
        "from sklearn.impute import SimpleImputer\r\n",
        "from sklearn.compose import make_column_transformer\r\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder,LabelEncoder,MinMaxScaler\r\n",
        "from sklearn.compose import make_column_selector\r\n",
        "# Model Building and Evaluation modules\r\n",
        "from sklearn.model_selection import cross_validate,GridSearchCV\r\n",
        "from sklearn.pipeline import make_pipeline\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "from sklearn.model_selection import cross_val_predict\r\n",
        "\r\n",
        "from sklearn.preprocessing import normalize\r\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder,OrdinalEncoder\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.naive_bayes import MultinomialNB\r\n",
        "from sklearn.naive_bayes import BernoulliNB\r\n",
        "from sklearn.naive_bayes import CategoricalNB\r\n",
        "from sklearn.linear_model import LinearRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "from xgboost import XGBClassifier\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\r\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "from sklearn.naive_bayes import GaussianNB\r\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.tree import DecisionTreeClassifier\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.svm import SVC\r\n",
        "from sklearn.neural_network import MLPClassifier\r\n",
        "from xgboost import XGBClassifier, XGBRFClassifier\r\n",
        "from xgboost import plot_tree, plot_importance\r\n",
        "\r\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\r\n",
        "from sklearn import preprocessing\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.feature_selection import RFE\r\n",
        "\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J8rv74lSrYE"
      },
      "source": [
        "fr  = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Practice Data Set/Fertilizer Prediction.csv\")\r\n",
        "fr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFP29deCSs_4"
      },
      "source": [
        "fr.info()\r\n",
        "fr.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MDRjyXoZmSz"
      },
      "source": [
        "fr.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bApbLTD2Z9wB"
      },
      "source": [
        "sns.heatmap(fr.corr(), annot=True)\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJI4ry3Ma8qa"
      },
      "source": [
        "ct=make_column_transformer((MinMaxScaler(),make_column_selector(dtype_include= np.number)),\r\n",
        "                           (OneHotEncoder(),make_column_selector(dtype_include=object)))\r\n",
        "print(ct)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gbVWZWTbE7-"
      },
      "source": [
        "X=fr.iloc[0:,:8]\r\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNYj8jVkbnYm"
      },
      "source": [
        "X=ct.fit_transform(X)\r\n",
        "print(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeleKTZFb4Zu"
      },
      "source": [
        "lb=LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwOjKstJcLJT"
      },
      "source": [
        "y=fr['Fertilizer Name']\r\n",
        "y=lb.fit_transform(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Y4zyesXcq8A"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eoCmrGtdG5d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101) \r\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.1, random_state=42)\r\n",
        "\r\n",
        "print(f'Total # of sample in whole dataset: {len(X)}')\r\n",
        "print(f'Total # of sample in train dataset: {len(X_train)}')\r\n",
        "print(f'Total # of sample in validation dataset: {len(X_valid)}')\r\n",
        "print(f'Total # of sample in test dataset: {len(X_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I4WX6fHdSgi"
      },
      "source": [
        "models = {\r\n",
        "    'GaussianNB': GaussianNB(),\r\n",
        "    'MultinomialNB': MultinomialNB(),\r\n",
        "    'BernoulliNB': BernoulliNB(),\r\n",
        "    'LogisticRegression': LogisticRegression(),\r\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\r\n",
        "    'SupportVectorMachine': SVC(),\r\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\r\n",
        "    'KNeighborsClassifier': KNeighborsClassifier(),\r\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\r\n",
        "    'Stochastic Gradient Descent':  SGDClassifier(max_iter=5000, random_state=0),\r\n",
        "    'Neural Nets': MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5000, 10), random_state=1),\r\n",
        "    'XGBClassifier': XGBClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "modelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\r\n",
        "             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\r\n",
        "             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\r\n",
        "\r\n",
        "trainScores = []\r\n",
        "validationScores = []\r\n",
        "testScores = []\r\n",
        "\r\n",
        "for m in models:\r\n",
        "  model = models[m]\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  score = model.score(X_valid, y_valid)\r\n",
        "  #print(f'{m} validation score => {score*100}')\r\n",
        "    \r\n",
        "  print(f'{m}') \r\n",
        "  train_score = model.score(X_train, y_train)\r\n",
        "  print(f'Train score of trained model: {train_score*100}')\r\n",
        "  trainScores.append(train_score*100)\r\n",
        "\r\n",
        "  validation_score = model.score(X_valid, y_valid)\r\n",
        "  print(f'Validation score of trained model: {validation_score*100}')\r\n",
        "  validationScores.append(validation_score*100)\r\n",
        "\r\n",
        "  test_score = model.score(X_test, y_test)\r\n",
        "  print(f'Test score of trained model: {test_score*100}')\r\n",
        "  testScores.append(test_score*100)\r\n",
        "  print(\" \")\r\n",
        "    \r\n",
        "  y_predictions = model.predict(X_test)\r\n",
        "  conf_matrix = confusion_matrix(y_predictions, y_test)\r\n",
        "\r\n",
        "  print(f'Confussion Matrix: \\n{conf_matrix}\\n')\r\n",
        "\r\n",
        "  predictions = model.predict(X_test)\r\n",
        "  cm = confusion_matrix(predictions, y_test)\r\n",
        "\r\n",
        "  tn = conf_matrix[0,0]\r\n",
        "  fp = conf_matrix[0,1]\r\n",
        "  tp = conf_matrix[1,1]\r\n",
        "  fn = conf_matrix[1,0]\r\n",
        "  accuracy  = (tp + tn) / (tp + fp + tn + fn)\r\n",
        "  precision = tp / (tp + fp)\r\n",
        "  recall    = tp / (tp + fn)\r\n",
        "  f1score  = 2 * precision * recall / (precision + recall)\r\n",
        "  specificity = tn / (tn + fp)\r\n",
        "  print(f'Accuracy : {accuracy}')\r\n",
        "  print(f'Precision: {precision}')\r\n",
        "  print(f'Recall   : {recall}')\r\n",
        "  print(f'F1 score : {f1score}')\r\n",
        "  print(f'Specificity : {specificity}')\r\n",
        "  print(\"\") \r\n",
        "  print(f'Classification Report: \\n{classification_report(predictions, y_test)}\\n')\r\n",
        "  print(\"\")\r\n",
        "   \r\n",
        "  for m in range (1):\r\n",
        "    current = modelNames[m]\r\n",
        "    modelNames.remove(modelNames[m])\r\n",
        "\r\n",
        "  preds = model.predict(X_test)\r\n",
        "  confusion_matr = confusion_matrix(y_test, preds) #normalize = 'true'\r\n",
        "  plt.figure(figsize = (16,10))\r\n",
        "  plt.title(f'Fertilizer_Prediction   -   Model: {current}   -   Accuracy: {test_score*100}')\r\n",
        "  sns.heatmap(confusion_matr, cmap=\"Blues\", annot=True, annot_kws={\"size\": 16},\r\n",
        "              xticklabels = ['Target - 0', 'Target - 6'],\r\n",
        "             yticklabels=['Target - 0', 'Target - 6']);\r\n",
        "  #plt.savefig(f'{current}.jpg')\r\n",
        "  print(\"############################################################################\")\r\n",
        "  print(\"\")\r\n",
        "  print(\"\")\r\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGXm1d0pdcMb"
      },
      "source": [
        "plt.figure(figsize=(20,10))\r\n",
        "plt.title('Train - Validation - Test Scores of Models', fontweight='bold', size = 24)\r\n",
        "\r\n",
        "barWidth = 0.25\r\n",
        " \r\n",
        "bars1 = trainScores\r\n",
        "bars2 = validationScores\r\n",
        "bars3 = testScores\r\n",
        " \r\n",
        "r1 = np.arange(len(bars1))\r\n",
        "r2 = [x + barWidth for x in r1]\r\n",
        "r3 = [x + barWidth for x in r2]\r\n",
        " \r\n",
        "plt.bar(r1, bars1, color='darkcyan', width=barWidth, edgecolor='white', label='train', yerr=0.5,ecolor=\"black\",capsize=10)\r\n",
        "plt.bar(r2, bars2, color='forestgreen', width=barWidth, edgecolor='white', label='validation', yerr=0.5,ecolor=\"black\",capsize=10, alpha = .50)\r\n",
        "plt.bar(r3, bars3, color='skyblue', width=barWidth, edgecolor='white', label='test', yerr=0.5,ecolor=\"black\",capsize=10, hatch = '-')\r\n",
        " \r\n",
        "modelNames = [\"GaussianNB\",\"MultinomialNB\",'BernoulliNB','LogisticRegression','RandomForestClassifier','SupportVectorMachine',\r\n",
        "             'DecisionTreeClassifier', 'KNeighborsClassifier','GradientBoostingClassifier',\r\n",
        "             'Stochastic Gradient Descent', 'Neural Nets', 'XGBClassifier']\r\n",
        "    \r\n",
        "plt.xlabel('Algorithms', fontweight='bold', size = 24)\r\n",
        "plt.ylabel('Scores', fontweight='bold', size = 24)\r\n",
        "plt.xticks([r + barWidth for r in range(len(bars1))], modelNames, rotation = 75)\r\n",
        " \r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1af7tBU_d5d2"
      },
      "source": [
        "for i in range(12):\r\n",
        "    print(f'Accuracy of {modelNames[i]} -----> {testScores[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9paw3TmkeDKe"
      },
      "source": [
        "models = {\r\n",
        "    'MultinomialNB': MultinomialNB(),\r\n",
        "    'BernoulliNB': BernoulliNB(),\r\n",
        "    'LogisticRegression': LogisticRegression(),\r\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\r\n",
        "    'DecisionTreeClassifier': DecisionTreeClassifier(),\r\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\r\n",
        "    'Stochastic Gradient Descent':  SGDClassifier(max_iter=5000, random_state=0),\r\n",
        "    'XGBClassifier': XGBClassifier()\r\n",
        "}\r\n",
        "\r\n",
        "for m in models:\r\n",
        "  model = models[m]\r\n",
        "  model.fit(X_train, y_train)\r\n",
        "  \r\n",
        "  print(f'{m}') \r\n",
        "  best_features = SelectFromModel(model)\r\n",
        "  best_features.fit(X, y)\r\n",
        "\r\n",
        "  transformedX = best_features.transform(X)\r\n",
        "  print(f\"Old Shape: {X.shape} New shape: {transformedX.shape}\")\r\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-XOGgtUeJVg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}